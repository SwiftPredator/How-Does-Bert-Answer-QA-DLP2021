{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "orig_nbformat": 4,
    "colab": {
      "name": "code_improvements.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "language_info": {
      "name": "python",
      "version": "3.8.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.10 64-bit"
    },
    "interpreter": {
      "hash": "b6f5aa6c83ab6bb418a26169cae6e1f2aa26236cb3670b5bbe663715684b9fc3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Introduction:** In this notebook we compare the speed of edge probing of the following three implementations\n",
        "*   jiant 1.3.2\n",
        "*   jiant 2.2.0\n",
        "*   our own implementation (https://github.com/SwiftPredator/How-Does-Bert-Answer-QA-DLP2021/blob/main/src/probing-tasks/replicate/probing_tasks.ipynb)\n",
        "\n",
        "\n",
        "Before running make sure to set the runtime type to GPU (both jiant versions don't support TPUs)."
      ],
      "metadata": {
        "id": "tlrsfc8BuObA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**jiant 1.3.2:** First we install the dependencies for jiant 1.3.2 and clone the repository."
      ],
      "metadata": {
        "id": "eaZ_WukYUR4o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!pip install allennlp==0.8.4\n",
        "!pip install overrides==3.1.0\n",
        "!pip install jsondiff\n",
        "!pip install sacremoses\n",
        "!pip install pyhocon==0.3.35\n",
        "!pip install transformers==2.6.0\n",
        "!pip install python-Levenshtein==0.12.0\n",
        "!pip install tensorflow==1.15.0\n",
        "\n",
        "!python -m nltk.downloader perluniprops nonbreaking_prefixes punkt\n",
        "\n",
        "!pip uninstall overrides\n",
        "!pip install overrides==3.1.0\n",
        "\n",
        "!pip install tensorflow==1.15"
      ],
      "outputs": [],
      "metadata": {
        "id": "jNBGQ6F3uObA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Restart the runtime now. Clone the jiant and OntoNotes repository and set some environment variables."
      ],
      "metadata": {
        "id": "6V55oNT0uObA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!git clone --branch v1.3.2  --recursive https://github.com/nyu-mll/jiant.git jiant\n",
        "!git clone https://github.com/yuchenlin/OntoNotes-5.0-NER-BIO.git\n",
        "\n",
        "import os\n",
        "os.environ['JIANT_PROJECT_PREFIX'] = \"/content/output\"\n",
        "os.environ['JIANT_DATA_DIR'] = \"/content/data\"\n",
        "os.environ['WORD_EMBS_FILE'] = \"/content/embs\""
      ],
      "outputs": [],
      "metadata": {
        "id": "oN6RTSBauObA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copy the ontonotes path (/content/OntoNotes-5.0-NER-BIO/conll-formatted-ontonotes-5.0) to /content/jiant/probing/get_and_process_all_data.sh\n",
        "Comment out SPR data and tokenizing for OpenAI, Moses and bert-large in /content/jiant/probing/get_and_process_all_data.sh. Set JIANT_DATA_DIR to \"/content/data\". Run the next cell to preprocess the data"
      ],
      "metadata": {
        "id": "AuoHlz3puObA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%cd /content/\n",
        "!./jiant/probing/get_and_process_all_data.sh"
      ],
      "outputs": [],
      "metadata": {
        "id": "ez-JIjiNuObA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Afterwards save the data to Google Drive."
      ],
      "metadata": {
        "id": "jQWovUcZlxQY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!cp -r \"/content/data\" \"/content/drive/MyDrive/data\""
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDm_3u62k7Ok",
        "outputId": "bd27c03d-5ed2-4dd2-c0b7-b1b961a22e62"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you have already preprocessed and saved the data, you can just load it from Google Drive."
      ],
      "metadata": {
        "id": "oajV3QUxlHMM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!cp -r \"/content/drive/MyDrive/data\" \"/content/data\""
      ],
      "outputs": [],
      "metadata": {
        "id": "6OX073UslSOc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before running the next cell go to /content/jiant/jiant/config/defaults.conf and set max_vals in edges-tmpl-large and edges-tmpl-small to 5 and val_interval in edges-tmpl and edges-tmpl-small to 1000. Restart the runtime afterwards."
      ],
      "metadata": {
        "id": "xWwqCf1PmLxk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To circumvent any difficulties with adding tasks, we just time tasks that are already implemented in jiant. For some reason the runtime has to be factory reset after each task."
      ],
      "metadata": {
        "id": "VrXYXHBSuObA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "tasks = [\n",
        "    #\"edges-ner-ontonotes\", \n",
        "    #\"edges-rel-semeval\",\n",
        "    \"edges-coref-ontonotes\",\n",
        "    ]\n",
        "\n",
        "models = [\n",
        "    \"bert-base-uncased\", \n",
        "    ]"
      ],
      "outputs": [],
      "metadata": {
        "id": "HNJkPEyeuObA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%cd /content/jiant/\n",
        "\n",
        "import jiant.__main__ as main\n",
        "from timeit import default_timer as timer\n",
        "import os\n",
        "import json\n",
        "\n",
        "os.environ[\"JIANT_PROJECT_PREFIX\"] = \"/content/output/\"\n",
        "os.environ[\"JIANT_DATA_DIR\"] = \"/content/data/\"\n",
        "os.environ[\"WORD_EMBS_FILE\"] = \"/content/embs/\"\n",
        "\n",
        "with open(\"/content/results.json\", \"r\") as f:\n",
        "    results = json.load(f)\n",
        "if results is None:\n",
        "    results = {}\n",
        "\n",
        "implementation_results = results.setdefault(\"jiant 1.3.2\", {})\n",
        "\n",
        "for model in models:\n",
        "    implementation_results[model] = {}\n",
        "    for task in tasks:\n",
        "        start = timer()\n",
        "        main.main([\n",
        "                   \"--config_file\",\n",
        "                   \"/content/jiant/jiant/config/edgeprobe/edgeprobe_bert.conf\",\n",
        "                   \"-o\",\n",
        "                   f\"target_tasks={task},exp_name=timeit,input_module={model},max_seq_len=384\"\n",
        "                   ])\n",
        "        end = timer()\n",
        "        implementation_results[model][task] = end - start\n",
        "\n",
        "print(results)\n",
        "with open(\"/content/results.json\", \"w\") as f:\n",
        "    json.dump(results, f)"
      ],
      "outputs": [],
      "metadata": {
        "id": "aNbOy1-euObA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**jiant 2.2.0:** We follow the same steps as in the reproduced notebook."
      ],
      "metadata": {
        "id": "Z3wwnSUnWK7g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!git clone https://github.com/SwiftPredator/How-Does-Bert-Answer-QA-DLP2021.git\n",
        "\n",
        "# copy the modified jiant lib to the /content/\n",
        "!mv \"/content/How-Does-Bert-Answer-QA-DLP2021/src/probing-tasks/jiant\" \"/content/\"\n",
        "\n",
        "%cd jiant\n",
        "!pip install -r requirements-no-torch.txt\n",
        "!pip install --no-deps -e ./\n",
        "!pip install gdown  # lib to download file from googlde drive link"
      ],
      "outputs": [],
      "metadata": {
        "id": "kXlrNxdbrnN0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Restart the runtime now. When restarting the runtime run from here on."
      ],
      "metadata": {
        "id": "CBakOl4Vr9Cs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%cd /content/jiant\n",
        "\n",
        "import jiant.utils.python.io as py_io\n",
        "import jiant.utils.display as display\n",
        "import os\n",
        "\n",
        "def init_task_config(task_name, size):\n",
        "    jiant_task = task_name\n",
        "    if(task_name == \"sup-squad\" or task_name == \"sup-babi\"):\n",
        "        jiant_task = \"coref\"  # use coref task to probe supporting facts task because of the analog structure of jiant EP json format\n",
        "\n",
        "    os.makedirs(\"/content/tasks/configs/\", exist_ok=True)\n",
        "    os.makedirs(f\"/content/tasks/data/{task_name}\", exist_ok=True)\n",
        "\n",
        "    py_io.write_json({\n",
        "        \"task\": jiant_task,\n",
        "        \"paths\": {\n",
        "        \"train\": f\"/content/tasks/data/{task_name}/{size}/train.jsonl\",\n",
        "        \"val\":   f\"/content/tasks/data/{task_name}/{size}/val.jsonl\",\n",
        "        },\n",
        "        \"name\": jiant_task\n",
        "        }, f\"/content/tasks/configs/{task_name}_config.json\")\n",
        "\n",
        "task_names = [\n",
        "              \"ner\", \n",
        "              \"semeval\", \n",
        "              \"coref\",    \n",
        "              #\"ques\" \n",
        "              #\"sup-squad\", \n",
        "              #\"sup-babi\",\n",
        "              #\"sup-hotpot\",\n",
        "             ]\n",
        "\n",
        "size = \"timing\"\n",
        "\n",
        "for task_name in task_names:\n",
        "    init_task_config(task_name, size)"
      ],
      "outputs": [],
      "metadata": {
        "id": "ahdYHAyB9MPY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "# copy the task data to the tasks folder created above\n",
        "!cp -r \"/content/How-Does-Bert-Answer-QA-DLP2021/src/probing-tasks/data\" \"/content/tasks/\""
      ],
      "outputs": [],
      "metadata": {
        "id": "yMS-ONre-5Os"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import jiant.proj.main.export_model as export_model\n",
        "\n",
        "models = [\n",
        "          \"bert-base-uncased\", \n",
        "          ]\n",
        "\n",
        "for model in models:\n",
        "    export_model.export_model(\n",
        "        hf_pretrained_model_name_or_path=model,\n",
        "        output_base_path=f\"/content/models/{model}\",\n",
        "        )"
      ],
      "outputs": [],
      "metadata": {
        "id": "sTtTLW19-1M4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import jiant.shared.caching as caching\n",
        "import jiant.proj.main.tokenize_and_cache as tokenize_and_cache\n",
        "\n",
        "seq_length_options = {\n",
        "    \"ner\":        384, \n",
        "    \"semeval\":    384, \n",
        "    \"coref\":      384,\n",
        "    \"ques\":       128,     \n",
        "    \"sup-squad\":  384, \n",
        "    \"sup-babi\":   384,\n",
        "    \"sup-hotpot\": 384,\n",
        "    }\n",
        "\n",
        "# Tokenize and cache each task\n",
        "def tokenize(task_name, model):\n",
        "    tokenize_and_cache.main(tokenize_and_cache.RunConfiguration(\n",
        "        task_config_path=f\"/content/tasks/configs/{task_name}_config.json\",\n",
        "        hf_pretrained_model_name_or_path=model,\n",
        "        output_dir=f\"/content/cache/{task_name}\",\n",
        "        phases=[\"train\", \"val\"],\n",
        "        max_seq_length=seq_length_options[task_name],\n",
        "        ))\n",
        "\n",
        "for task_name in task_names:\n",
        "    for model in models:\n",
        "        tokenize(task_name, model)\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "-hkcpGYUsQR8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "import jiant.proj.main.scripts.configurator as configurator\n",
        "\n",
        "def create_jiant_task_config(task_name):\n",
        "    jiant_run_config = configurator.SimpleAPIMultiTaskConfigurator(\n",
        "        task_config_base_path=\"/content/tasks/configs\",\n",
        "        task_cache_base_path=\"/content/cache\",\n",
        "        train_task_name_list=[task_name],\n",
        "        val_task_name_list=[task_name],\n",
        "        train_batch_size=32,\n",
        "        eval_batch_size=32,\n",
        "        epochs=50,\n",
        "        num_gpus=1,\n",
        "        ).create_config()\n",
        "    os.makedirs(\"/content/tasks/run_configs/\", exist_ok=True)\n",
        "    py_io.write_json(jiant_run_config, f\"/content/tasks/run_configs/{task_name}_run_config.json\")\n",
        "    #display.show_json(jiant_run_config)"
      ],
      "outputs": [],
      "metadata": {
        "id": "WEF4WdQ1sXNs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "import jiant.proj.main.runscript as main_runscript\n",
        "\n",
        "def run_probing_task(task_name, model_name=\"bert-base-uncased\", num_layers=1, bin_model_path=\"\"):\n",
        "    hf_model_name = model_name\n",
        "    if(model_name == \"bert-babi\"):\n",
        "        hf_model_name = \"bert-base-uncased\"\n",
        "    \n",
        "    run_args = main_runscript.RunConfiguration(\n",
        "        jiant_task_container_config_path=f\"/content/tasks/run_configs/{task_name}_run_config.json\",\n",
        "        output_dir=f\"/content/tasks/runs/{task_name}\",\n",
        "        hf_pretrained_model_name_or_path=hf_model_name,\n",
        "        model_path=f\"/content/models/{model_name}/model/model.p\",\n",
        "        model_config_path=f\"/content/models/{model_name}/model/config.json\",\n",
        "        learning_rate=1e-2,\n",
        "        eval_every_steps=100,\n",
        "        do_train=True,\n",
        "        do_val=True,\n",
        "        do_save=True,\n",
        "        force_overwrite=True,\n",
        "        num_hidden_layers=num_layers,\n",
        "        bin_model_path=bin_model_path,\n",
        "        )\n",
        "    return main_runscript.run_loop(run_args)"
      ],
      "outputs": [],
      "metadata": {
        "id": "F5XrDdPkscfM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "from timeit import default_timer as timer\n",
        "\n",
        "def probe(model, task_name, n_layers, dataset_size):\n",
        "    init_task_config(task_name, dataset_size)\n",
        "    #tokenize(task_name, model)\n",
        "    create_jiant_task_config(task_name)\n",
        "    start = timer()\n",
        "    run_probing_task(task_name, model, n_layers)\n",
        "    end = timer()\n",
        "    return end - start"
      ],
      "outputs": [],
      "metadata": {
        "id": "JZ-wI6v0s0lY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To avoid lenghty tokenization and caching we run for 50 epochs instead of 5, use train datasets with size 320 (10 batches) and evaluate every 100 steps. The results have to be multiplied by 10 to be comparable to the other implementations."
      ],
      "metadata": {
        "id": "_xPmO_qjBMsM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "if os.path.isfile(\"/content/results.json\"):\n",
        "    with open(\"/content/results.json\", \"w\") as f:\n",
        "        results = json.load(f)\n",
        "else:\n",
        "    results = {}\n",
        "\n",
        "implementation_results = results.setdefault(\"jiant 2.2.0\", {})\n",
        "\n",
        "for model in models:\n",
        "    implementation_results[model] = {}\n",
        "    for task in task_names:\n",
        "        implementation_results[model][task] = probe(model, task, 1, \"test\") * 10\n",
        "\n",
        "print(results)\n",
        "with open(\"/content/results.json\", \"w\") as f:\n",
        "    json.dump(results, f)"
      ],
      "outputs": [],
      "metadata": {
        "id": "lY_YFqkAtGI0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Our own implementation:** Change the runtime to TPU now and run the following cell to install our code. Restart the runtime afterwards.\n"
      ],
      "metadata": {
        "id": "CEY2QI5BuObA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!git clone https://github.com/SwiftPredator/How-Does-Bert-Answer-QA-DLP2021/\n",
        "\n",
        "!mv \"/content/How-Does-Bert-Answer-QA-DLP2021/src/probing-tasks/data\" \"/content/\"\n",
        "!mv \"/content/How-Does-Bert-Answer-QA-DLP2021/src/probing-tasks/replicate\" \"/content/\"\n",
        "\n",
        "%cd /content/replicate\n",
        "!pip install -r requirements.txt\n",
        "!pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl"
      ],
      "outputs": [],
      "metadata": {
        "id": "cvcctBJOuObA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%cd /content/replicate\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "from edge_probing_utils import (\n",
        "    JiantDatasetSingleSpan,\n",
        "    JiantDatasetTwoSpan\n",
        "    )\n",
        "import edge_probing as ep\n",
        "import edge_probing_tpu as ep_tpu"
      ],
      "outputs": [],
      "metadata": {
        "id": "imh-nQRPuObA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "tasks = [\n",
        "    \"ner\", \n",
        "    \"semeval\",\n",
        "    \"coref\",\n",
        "    ]\n",
        "\n",
        "task_types = {\n",
        "    \"ner\": \"single_span\", \n",
        "    \"semeval\": \"single_span\",\n",
        "    \"coref\": \"two_span\",\n",
        "    }\n",
        "\n",
        "models = [\n",
        "    \"bert-base-uncased\", \n",
        "    ]\n",
        "\n",
        "task_labels_to_ids = {\n",
        "    \"ner\": {'ORDINAL': 0, 'DATE': 1, 'PERSON': 2, 'LOC': 3, 'GPE': 4, 'QUANTITY': 5, 'ORG': 6, 'WORK_OF_ART': 7, 'CARDINAL': 8, 'TIME': 9, 'MONEY': 10, 'LANGUAGE': 11, 'NORP': 12, 'PERCENT': 13, 'EVENT': 14, 'LAW': 15, 'FAC': 16, 'PRODUCT': 17},\n",
        "    \"coref\": {\"0\": 0, \"1\": 1},\n",
        "    \"semeval\": {'Component-Whole(e2,e1)': 0, 'Other': 1, 'Instrument-Agency(e2,e1)': 2, 'Member-Collection(e1,e2)': 3, 'Entity-Destination(e1,e2)': 4, 'Content-Container(e1,e2)': 5, 'Message-Topic(e1,e2)': 6, 'Cause-Effect(e2,e1)': 7, 'Product-Producer(e2,e1)': 8, 'Member-Collection(e2,e1)': 9, 'Entity-Origin(e1,e2)': 10, 'Cause-Effect(e1,e2)': 11, 'Component-Whole(e1,e2)': 12, 'Message-Topic(e2,e1)': 13, 'Product-Producer(e1,e2)': 14, 'Entity-Origin(e2,e1)': 15, 'Content-Container(e2,e1)': 16, 'Instrument-Agency(e1,e2)': 17, 'Entity-Destination(e2,e1)': 18},\n",
        "    }"
      ],
      "outputs": [],
      "metadata": {
        "id": "Di7xEXw9uObA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "import os\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "loss_function = nn.BCELoss()\n",
        "batch_size = 32\n",
        "num_layers = [12]\n",
        "num_workers = 0\n",
        "\n",
        "device = xm.xla_device()\n",
        "\n",
        "# Disable warnings.\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "\n",
        "def probe(model, task, size):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model)\n",
        "    train_data = ep.tokenize_jiant_dataset(\n",
        "            tokenizer,\n",
        "            *(ep.read_jiant_dataset(f\"/content/data/{task}/{size}/train.jsonl\")),\n",
        "            task_labels_to_ids[task],\n",
        "            )\n",
        "    val_data = ep.tokenize_jiant_dataset(\n",
        "            tokenizer,\n",
        "            *(ep.read_jiant_dataset(f\"/content/data/{task}/{size}/val.jsonl\")),\n",
        "            task_labels_to_ids[task],\n",
        "            )\n",
        "    test_data = ep.tokenize_jiant_dataset(\n",
        "            tokenizer,\n",
        "            *(ep.read_jiant_dataset(f\"/content/data/{task}/{size}/test.jsonl\")),\n",
        "            task_labels_to_ids[task],\n",
        "            )\n",
        "    if task_types[task] == \"single_span\":\n",
        "        train_data = JiantDatasetSingleSpan(train_data)\n",
        "        val_data = JiantDatasetSingleSpan(val_data)\n",
        "        test_data = JiantDatasetSingleSpan(test_data)\n",
        "    elif task_types[task] == \"two_span\":\n",
        "        train_data = JiantDatasetTwoSpan(train_data)\n",
        "        val_data = JiantDatasetTwoSpan(val_data)\n",
        "        test_data = JiantDatasetTwoSpan(test_data)\n",
        "    train_loader = data.DataLoader(train_data, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=num_workers)\n",
        "    val_loader = data.DataLoader(val_data, batch_size=batch_size, pin_memory=True, num_workers=num_workers)\n",
        "    test_loader = data.DataLoader(test_data, batch_size=batch_size, pin_memory=True, num_workers=num_workers)\n",
        "    start = timer()\n",
        "    ep_tpu.probing(ep.ProbeConfig(\n",
        "        train_loader,\n",
        "        val_loader,\n",
        "        test_loader,\n",
        "        model,\n",
        "        num_layers,\n",
        "        loss_function,\n",
        "        task_labels_to_ids[task],\n",
        "        task_types[task],\n",
        "        lr=0.0001,\n",
        "        max_evals=5,\n",
        "        eval_interval=1000,\n",
        "        dev=device,\n",
        "        ))\n",
        "    end = timer()\n",
        "    return end - start\n",
        "\n",
        "with open(\"/content/results.json\", \"r\") as f:\n",
        "    results = json.load(f)\n",
        "if results is None:\n",
        "    results = {}\n",
        "\n",
        "implementation_results = results.setdefault(\"jiant 1.3.2\", {})\n",
        "\n",
        "for model in models:\n",
        "    implementation_results[model] = {}\n",
        "    for task in tasks:\n",
        "        implementation_results[model][task] = probe(model, task, \"big\")\n",
        "\n",
        "print(results)\n",
        "with open(\"/content/results.json\", \"w\") as f:\n",
        "    json.dump(results, f)"
      ],
      "outputs": [],
      "metadata": {
        "id": "cA2WsyRkuObA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualization:** Change the task names in /content/results.json to be the same for all implementations"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "\n",
        "with open(\"/content/results.json\", \"r\") as f:\n",
        "    results = json.load(f)\n",
        "\n",
        "task_to_title = {\n",
        "    \"coref\": \"coref\",\n",
        "    \"ques\": \"ques\",\n",
        "    \"sup-squad\": \"sup SQuAD\",\n",
        "    \"sup-babi\": \"sup bAbI\",\n",
        "    \"ner\": \"ner\",\n",
        "    \"semeval\": \"rel\",\n",
        "    \"adversarialqa\": \"adversarialQA\"\n",
        "    }\n",
        "\n",
        "for implementation in results.keys():\n",
        "    plt.scatter(\n",
        "        [task_to_title[key] for key in results[implementation][\"bert-base-uncased\"].keys()],\n",
        "        list(results[implementation][\"bert-base-uncased\"].values()),\n",
        "        )\n",
        "\n",
        "plt.legend(list(results.keys())) \n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "metadata": {}
    }
  ]
}